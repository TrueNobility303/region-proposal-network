import torch
import torch.nn as nn
import torchvision.models as tvmodel
from torchsummary import summary 
import torch.nn.functional as F
from data import myCityscapes
from data import jsonTransform
from torchvision import transforms
import torchvision 
from torch.utils.data import DataLoader
from config import * 

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

class YOLONET(nn.Module):
    def __init__(self):
        super().__init__()
        #使用resnet34作为预训练的模型，去除(线性层)最后两层
        resnet = tvmodel.resnet34(pretrained=True) 
        for layer in resnet.children():
            layer.requires_grad = False
        resnet_out_channel = resnet.fc.in_features  
        self.resnet = nn.Sequential(*list(resnet.children())[:-2])  
        self.resnet.eval()

        #resnet输出 [-1,512,14,14]
        self.Conv_layers = nn.Sequential(
            nn.Conv2d(resnet_out_channel, 1024, 3, padding=1),
            nn.BatchNorm2d(1024), 
            nn.LeakyReLU(inplace=True),
            nn.Conv2d(1024, 1024, 3, stride=2, padding=1),
            nn.BatchNorm2d(1024),
            nn.LeakyReLU(inplace=True),
            nn.Conv2d(1024, 1024, 3, padding=1),
            nn.BatchNorm2d(1024),
            nn.LeakyReLU(inplace=True),
            nn.Conv2d(1024, 1024, 3, padding=1),
            nn.BatchNorm2d(1024),
            nn.LeakyReLU(inplace=True),
        )
        #卷积层输出 [-1,1024,7,7]

        # 定义YOLO的最后的全连接层和box及分类头
        self.Conn_layers = nn.Sequential(
            nn.Linear(49 * 1024, 4096),
            nn.LeakyReLU(inplace=True),
        )
        self.boxHead = nn.Sequential(
            nn.Linear(4096, NUMGRID *  NUMGRID * NUMBBOX * 4),
            nn.Sigmoid()
        )
        self.clsHead = nn.Sequential(
            nn.Linear(4096, NUMGRID *  NUMGRID * NUMBBOX),
            nn.Sigmoid()
        )

    def forward(self, inputs):
        inputs = F.interpolate(inputs,size=(448,448),mode='bilinear',align_corners=True)
        x = self.resnet(inputs)
        x = self.Conv_layers(x)
        x = x.view(x.size()[0], -1)
        x = self.Conn_layers(x)
        boxpred = self.boxHead(x)
        clspred = self.clsHead(x)
        boxpred = boxpred.reshape(-1,NUMGRID,NUMGRID,NUMBBOX,4)
        clspred = clspred.reshape(-1,NUMGRID,NUMGRID,NUMBBOX)
       
        return boxpred, clspred
class CONV5(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv_block1 = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, stride=2, ceil_mode=True),
        )

        self.conv_block2 = nn.Sequential(
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, stride=2, ceil_mode=True),
        )

        self.conv_block3 = nn.Sequential(
            nn.Conv2d(128, 256, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, stride=2, ceil_mode=True),
        )

        self.conv_block4 = nn.Sequential(
            nn.Conv2d(256, 512, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, stride=2, ceil_mode=True),
            nn.ReLU(inplace=True)
        )

    def forward(self,x):
        x = self.conv_block1(x)
        x = self.conv_block2(x)
        x = self.conv_block3(x)
        x = self.conv_block4(x)
        return x 
        
if __name__ == '__main__':
    net = YOLONET()
    boxpred,clspred = net(torch.zeros(1,3,448,448))
    print(boxpred.shape, clspred.shape)
    #YOLONET输出[-1,10,7,7]
    #net = YOLONET()
    #boxpred,clspred = net(torch.zeros(1,3,448,448))

class CLSTrainer():
    def __init__(self,img_size):
        self.epoches = 30
        self.lr = 0.01

        w,h = img_size
        self.anchors = gererate_all_anchor(num_gridx=w//16,num_gridy=h//16)
        self.model = FPN().to(device)
        self.optimizer = torch.optim.SGD(self.model.parameters(),lr=self.lr)
        self.box_loss_weight = 0
        self.pred_loss_weight = 1

    def train(self, dataloader, validloader):
        for e in range(self.epoches):
            tot_box_loss = 0
            tot_pred_loss = 0
            tot_num = 0
            for i,data in enumerate(tqdm.tqdm(dataloader)):
                #选取部分数据集训练
                if i > 100:
                    break
                else:
                    tot_num += 1
                img,target = data 
                bboxes,clses = target 
                img = img.to(device)
                bboxes = bboxes.to(device)
                clses = clses.to(device)
                pred_loc, pred_score = self.model(img)
                
                #随机选取一个样本
                img = img[0]
                bboxes = bboxes[0]
                clses = clses[0]
                pred_loc = pred_loc[0]
                pred_score = pred_score[0]
                
                #根据cls作为掩码获取bbox，没有bbox的不进行学习，利用bbox预先生成每个锚点需要学习的偏移量，并进行采样
                bboxes = bboxes[clses==1]
                if len(bboxes) == 0:
                    continue
                true_loc, labels = create_anchor_target(self.anchors, bboxes)
                if torch.sum(labels==1) == 0:
                    continue
                #取出loc中正样本的部分用smoothF1计算损失，score中正负样本的部分用MSEloss计算损失
                
                pred_loc = pred_loc[labels==1]
                true_loc = true_loc[labels==1]

                pos_pred_score = pred_score[labels==1]
                pos_true_score = labels[labels==1]
                neg_pred_score = pred_score[labels==0]
                neg_true_score = labels[labels==0]
                
                box_loss = self.box_loss_weight * F.smooth_l1_loss(pred_loc,true_loc)
                pred_loss = self.pred_loss_weight * (F.mse_loss(pos_pred_score, pos_true_score) + F.mse_loss(neg_pred_score,neg_true_score))
                loss = box_loss + pred_loss 
                tot_box_loss += box_loss.item()
                tot_pred_loss += pred_loss.item()

                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

            tot_box_loss /= tot_num
            tot_pred_loss /= tot_num
            print("e:",e,"box_loss:",tot_box_loss,"pred_loss:",tot_pred_loss)
            savepath = 'dump/' + str(e) +'.png'
            self.test(dataloader,savepath)

    @torch.no_grad()
    def test(self, dataloader, savepath):
        for i, data in enumerate(dataloader):
            if i>0:
                break 
            img,target = data 
            bboxes,clses = target 
            img = img.to(device)
            bboxes = bboxes.to(device)
            clses = clses.to(device)
            pred_loc, pred_score = self.model(img)
            
            #随机选取一个样本
            img = img[0]
            bboxes = bboxes[0]
            clses = clses[0]
            pred_loc = pred_loc[0]
            pred_score = pred_score[0]
            
            #根据cls作为掩码获取bbox，没有bbox的不进行学习，利用bbox预先生成每个锚点需要学习的偏移量，并进行采样
            bboxes = bboxes[clses==1]
            if len(bboxes) == 0:
                continue
            true_loc, labels = create_anchor_target(self.anchors, bboxes)
            true_box = loc2bbox(self.anchors, true_loc)
            
            """
            pred_bbox = loc2bbox(self.anchors, pred_loc)
            pred_bbox = pred_bbox[pred_score>0.9]
            pred_score = pred_score[pred_score>0.9]
            """

            true_box = true_box[pred_score>0.5]
            pred_score = pred_score[pred_score>0.5]
            print(pred_score)

            keep = nms(bbox_wh2xy(true_box),pred_score,0.4)
            true_box = true_box[keep]
            show_bboxes_compare_img(img,true_box,bboxes,savepath)

            #pred_bbox = pred_bbox[keep]
            #show_bboxes_compare_img(img,pred_bbox,bboxes,savepath)
