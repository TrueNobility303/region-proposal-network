import torch
import torch.nn as nn
import torchvision.models as tvmodel
from torchsummary import summary 

GL_CLASSES = ['person', 'bird', 'cat', 'cow', 'dog', 'horse', 'sheep',
           'aeroplane', 'bicycle', 'boat', 'bus', 'car', 'motorbike', 'train',
           'bottle', 'chair', 'diningtable', 'pottedplant', 'sofa', 'tvmonitor']


device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

class YOLONET(nn.Module):
    def __init__(self):
        super().__init__()
        #使用resnet34作为预训练的模型，去除(线性层)最后两层
        resnet = tvmodel.resnet34(pretrained=True)  
        resnet_out_channel = resnet.fc.in_features  
        self.resnet = nn.Sequential(*list(resnet.children())[:-2])  
        
        self.Conv_layers = nn.Sequential(
            nn.Conv2d(resnet_out_channel, 1024, 3, padding=1),
            nn.BatchNorm2d(1024), 
            nn.LeakyReLU(inplace=True),
            nn.Conv2d(1024, 1024, 3, stride=2, padding=1),
            nn.BatchNorm2d(1024),
            nn.LeakyReLU(inplace=True),
            nn.Conv2d(1024, 1024, 3, padding=1),
            nn.BatchNorm2d(1024),
            nn.LeakyReLU(inplace=True),
            nn.Conv2d(1024, 1024, 3, padding=1),
            nn.BatchNorm2d(1024),
            nn.LeakyReLU(inplace=True),
        )
        # 定义YOLO的最后2个全连接层
        self.Conn_layers = nn.Sequential(
            nn.Linear(GL_NUMGRID * GL_NUMGRID * 1024, 4096),
            nn.LeakyReLU(inplace=True),
            # 输出大小 5*GL_NUMBBOX+len(GL_CLASSES)
            nn.Linear(4096, GL_NUMGRID * GL_NUMGRID * (5*GL_NUMBBOX+len(GL_CLASSES))),
            nn.Sigmoid()  
        )

    def forward(self, inputs):
        print(inputs.shape)
        x = self.resnet(inputs)
        print(x.shape)
        x = self.Conv_layers(x)
        x = x.view(x.size()[0], -1)
        x = self.Conn_layers(x)
        self.pred = x.reshape(-1, (5 * GL_NUMBBOX + len(GL_CLASSES)), GL_NUMGRID, GL_NUMGRID)  
        return self.pred


    def calculate_loss(self, labels):
        self.pred = self.pred.double()
        labels = labels.double()
        num_gridx, num_gridy = GL_NUMGRID, GL_NUMGRID 
        #损失包含(正负样本的)置信度损失，坐标损失，类别损失
        noobj_confi_loss = 0.  
        coor_loss = 0.  
        obj_confi_loss = 0.  
        class_loss = 0.  
        n_batch = labels.size()[0]  

        for i in range(n_batch):  
            for n in range(num_gridx):  
                for m in range(num_gridy):  
                    if labels[i, 4, m, n] == 1:  
                        # 如果包含物体，将数据(px,py,w,h)转换为(x1,y1,x2,y2)
                        # 先将px,py转换为cx,cy，即相对网格的位置转换为标准化后实际的bbox中心位置cx,xy
                        # 然后再利用(cx-w/2,cy-h/2,cx+w/2,cy+h/2)转换为xyxy形式，用于计算iou
                        bbox1_pred_xyxy = ((self.pred[i, 0, m, n] + n) / num_gridx - self.pred[i, 2, m, n] / 2,
                                           (self.pred[i, 1, m, n] + m) / num_gridy - self.pred[i, 3, m, n] / 2,
                                           (self.pred[i, 0, m, n] + n) / num_gridx + self.pred[i, 2, m, n] / 2,
                                           (self.pred[i, 1, m, n] + m) / num_gridy + self.pred[i, 3, m, n] / 2)
                        bbox2_pred_xyxy = ((self.pred[i, 5, m, n] + n) / num_gridx - self.pred[i, 7, m, n] / 2,
                                           (self.pred[i, 6, m, n] + m) / num_gridy - self.pred[i, 8, m, n] / 2,
                                           (self.pred[i, 5, m, n] + n) / num_gridx + self.pred[i, 7, m, n] / 2,
                                           (self.pred[i, 6, m, n] + m) / num_gridy + self.pred[i, 8, m, n] / 2)
                        bbox_gt_xyxy = ((labels[i, 0, m, n] + n) / num_gridx - labels[i, 2, m, n] / 2,
                                        (labels[i, 1, m, n] + m) / num_gridy - labels[i, 3, m, n] / 2,
                                        (labels[i, 0, m, n] + n) / num_gridx + labels[i, 2, m, n] / 2,
                                        (labels[i, 1, m, n] + m) / num_gridy + labels[i, 3, m, n] / 2)
                        iou1 = calculate_iou(bbox1_pred_xyxy, bbox_gt_xyxy)
                        iou2 = calculate_iou(bbox2_pred_xyxy, bbox_gt_xyxy)
                        # 选择iou大的bbox作为负责物体
                        if iou1 >= iou2:
                            coor_loss = coor_loss + 5 * (torch.sum((self.pred[i, 0:2, m, n] - labels[i, 0:2, m, n]) ** 2) \
                                        + torch.sum((self.pred[i, 2:4, m, n].sqrt() - labels[i, 2:4, m, n].sqrt()) ** 2))
                            obj_confi_loss = obj_confi_loss + (self.pred[i, 4, m, n] - iou1) ** 2
                            noobj_confi_loss = noobj_confi_loss + 0.5 * ((self.pred[i, 9, m, n] - iou2) ** 2)
                        else:
                            coor_loss = coor_loss + 5 * (torch.sum((self.pred[i, 5:7, m, n] - labels[i, 5:7, m, n]) ** 2) \
                                        + torch.sum((self.pred[i, 7:9, m, n].sqrt() - labels[i, 7:9, m, n].sqrt()) ** 2))
                            obj_confi_loss = obj_confi_loss + (self.pred[i, 9, m, n] - iou2) ** 2
                            noobj_confi_loss = noobj_confi_loss + 0.5 * ((self.pred[i, 4, m, n] - iou1) ** 2)
                        class_loss = class_loss + torch.sum((self.pred[i, 10:, m, n] - labels[i, 10:, m, n]) ** 2)
                    else:  
                        noobj_confi_loss = noobj_confi_loss + 0.5 * torch.sum(self.pred[i, [4, 9], m, n] ** 2)

        loss = coor_loss + obj_confi_loss + noobj_confi_loss + class_loss
        return loss / n_batch

    #评价指标
    def calculate_metric(self, preds, labels):
        preds = preds.double()
        labels = labels[:, :(self.n_points*2)]
        l2_distance = torch.mean(torch.sum((preds-labels)**2, dim=1))
        return l2_distance


if __name__ == '__main__':
    x = torch.zeros(5,3,448,448).to(device)
    net = YOLONET().to(device)
    #summary(net,(3,448,448))
    a = net(x)
    print(a.shape)
    labels = torch.zeros(5, 30, 7, 7)
    loss = net.calculate_loss(labels)
    print(loss)

#输入img，box,cls输出显示检测结果并保存
def show_labels_img(img, boxes, clses, savepath):
    img = img.float().detach().cpu().permute(1,2,0).numpy()
    h,w,_ = img.shape
    boxes = boxes.detach().cpu().numpy()
    clses = clses.detach().cpu().numpy()

    ax =plt.subplot(1,1,1)
    plt.imshow(img)
    
    for box,cl in zip(bboxes,clses):
        if cl==0:
            continue
        else:
            box[0] = box[0]*2048
            box[1] = box[1]*1024
            box[2] = box[2]*2048
            box[3] = box[3]*1024

            ret = patches.Rectangle((box[0],box[1]),box[2],box[3],linewidth=1, edgecolor='r',facecolor='none') 
            ax.add_patch(ret)
    plt.axis('off')
    plt.savefig(savepath)

#定义不同格式bbox之间的转换，xy左上右下格式，wh为左上角加宽高格式，ct为中心点加宽高格式
def bbox_xy2wh(box1):
    box2 = torch.zeros(box1.shape)
    b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]
    box2[:,0] = b1_x1
    box2[:,1] = b1_y1
    box2[:,2] = b1_x2 - b1_x1
    box2[:,3] = b1_y2 - b1_y1 
    return box2

def bbox_wh2ct(box1):
    box2 = torch.zeros(box1.shape)
    x,y,w,h = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]
    box2[:,0] = x + w/2
    box2[:,1] = y + h/2
    box2[:,2] = w
    box2[:,3] = h
    return box2

def bbox_ct2wh(box1):
    box2 = torch.zeros(box1.shape)
    cx,cy,w,h = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]
    box2[:,0] = cx - w/2
    box2[:,1] = cy - h/2
    box2[:,2] = w
    box2[:,3] = h
    return box2